{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdiS31d5rxrR"
      },
      "source": [
        "# list of birds and their reference numbers\n",
        "0. American crow\n",
        "1. Blue Jay\n",
        "2. Vermillion flycatcher\n",
        "3. Western Grebe\n",
        "4. Yellow Warbler\n",
        "5. Cactus wren\n",
        "6. Indigo Bunting\n",
        "7. Eastern Towhee\n",
        "8. California Gull\n",
        "9. Ruby Throated Hummingbird"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "gbWGFk5fSVqy",
        "outputId": "5cffc17c-3b31-4dec-b118-7d78d888c1ca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-39b9d000556e>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "#import statements\n",
        "import random\n",
        "random.seed(100)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Reshape, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import cv2\n",
        "!pip install opencv-python\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "import itertools\n",
        "def revert(x):\n",
        "  return cv2.cvtColor(x, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RICM6cC27gth"
      },
      "outputs": [],
      "source": [
        "def draw_confusion_matrix(matrix, classes, title = \"confusion matrix\"):\n",
        "    '''\n",
        "        Draws a confusion matrix for the given target and predictions\n",
        "        Adapted from scikit-learn and discussion example.\n",
        "    '''\n",
        "    plt.cla()\n",
        "    plt.clf()\n",
        "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    num_classes = len(classes)\n",
        "    plt.xticks(np.arange(num_classes), classes, rotation=90)\n",
        "    plt.yticks(np.arange(num_classes), classes)\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = matrix.max() / 2.\n",
        "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
        "        plt.text(j, i, format(matrix[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_multiclass_roc(y_test, y_test_hat_cat, title = \"ROC\"):\n",
        "    n_classes = y_test_hat_cat.shape[1]\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_test_hat_cat[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_test_hat_cat.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    # Plot ROC curve for each class\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr[i], tpr[i], lw=2,\n",
        "                 label='ROC curve (AUC = %0.2f)' % roc_auc[i])\n",
        "\n",
        "    # Plot micro-average ROC curve\n",
        "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "             label='Micro-average ROC curve (AUC = %0.2f)' % roc_auc[\"micro\"],\n",
        "             linestyle=':', linewidth=4)\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Random classifier line\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"AUC scores:\")\n",
        "    for i in range(n_classes):\n",
        "        print(f\"Class {i}: {roc_auc[i]:.2f}\")\n",
        "    print(f\"Micro-average: {roc_auc['micro']:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-f3uH3Z9LtU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Aq6aqpk2j9"
      },
      "source": [
        "Converting bird images into numpy array\n",
        "\n",
        "# Note to self: if you want to change bird speices, then you need to re-save the numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOVt-o_Fusmn"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# paths = ['/content/drive/MyDrive/Research/Bird Images/images/029.American_Crow', \"/content/drive/MyDrive/Research/Bird Images/images/073.Blue_Jay\", '/content/drive/MyDrive/Research/Bird Images/images/042.Vermilion_Flycatcher', '/content/drive/MyDrive/Research/Bird Images/images/053.Western_Grebe', '/content/drive/MyDrive/Research/Bird Images/images/182.Yellow_Warbler', '/content/drive/MyDrive/Research/Bird Images/images/194.Cactus_Wren', '/content/drive/MyDrive/Research/Bird Images/images/014.Indigo_Bunting', '/content/drive/MyDrive/Research/Bird Images/images/021.Eastern_Towhee', '/content/drive/MyDrive/Research/Bird Images/images/059.California_Gull', '/content/drive/MyDrive/Research/Bird Images/images/068.Ruby_throated_Hummingbird']\n",
        "\n",
        "# arr = []\n",
        "\n",
        "# # Step 1: Find the largest dimensions among all images\n",
        "# max_height, max_width = 0, 0\n",
        "# for folder_path in paths:\n",
        "#     for filename in os.listdir(folder_path):\n",
        "#         image_path = os.path.join(folder_path, filename)\n",
        "#         image = cv2.imread(image_path)\n",
        "#         if image is not None:\n",
        "#             height, width = image.shape[:2]\n",
        "#             max_height = max(max_height, height)\n",
        "#             max_width = max(max_width, width)\n",
        "\n",
        "# # Step 2: Resize or pad images to the largest dimensions\n",
        "# for folder_path in paths:\n",
        "#     bird = []\n",
        "#     for filename in os.listdir(folder_path):\n",
        "#         image_path = os.path.join(folder_path, filename)\n",
        "#         image = cv2.imread(image_path)\n",
        "#         if image is not None:\n",
        "#             bird.append(cv2.resize(image, (max_width, max_height)))\n",
        "\n",
        "#     bird = np.array(bird)\n",
        "#     arr.append(bird)\n",
        "\n",
        "# # Now you have all the images with the same dimensions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qgz5TeNw-6E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXh6B29RwLcp"
      },
      "outputs": [],
      "source": [
        "# #saving array for later use\n",
        "# arr = np.array(arr)\n",
        "# np.save('/content/drive/MyDrive/Research/image_array_v3.npy', arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIPEGcWklVeY"
      },
      "outputs": [],
      "source": [
        "df = np.load(\"/content/drive/MyDrive/Research/image_array_v3.npy\", allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N28yPuP-hTA0"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9Ss4HDjwN3f"
      },
      "outputs": [],
      "source": [
        "for i in df:\n",
        "  print(i.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1fT46N1Y3YX"
      },
      "outputs": [],
      "source": [
        "for i in range(len(df)):\n",
        "    for j in range(len(df[i])):\n",
        "        df[i][j] = cv2.cvtColor(df[i][j], cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Apply data augmentation to each row\n",
        "augmented_df = df"
      ],
      "metadata": {
        "id": "1dZfkKTxQhDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = augmented_df"
      ],
      "metadata": {
        "id": "NEECJcj9RFIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP6GQ64R3E1y"
      },
      "outputs": [],
      "source": [
        "image = df[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEgccjaUYXDI"
      },
      "outputs": [],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2hONcHs3l2l"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CTMyteoiSKB"
      },
      "outputs": [],
      "source": [
        "#0: height, 1: width\n",
        "max_height = -1\n",
        "max_width = -1\n",
        "for i in df:\n",
        "  for j in i:\n",
        "    if j.shape[0] > max_height:\n",
        "      max_height = j.shape[0]\n",
        "    if j.shape[1] > max_width:\n",
        "      max_width = j.shape[1]\n",
        "\n",
        "print(\"max height:\" + str(max_height))\n",
        "print(\"max width:\" + str(max_width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9byPDin-hL2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "padded_df = np.zeros((len(df), len(df[0]), 500, 500, 3), dtype=np.uint8)\n",
        "\n",
        "for i, species_images in enumerate(df):\n",
        "    for j, image in enumerate(species_images):\n",
        "        padded_image = np.pad(image, ((0, 500 - image.shape[0]), (0, 500 - image.shape[1]), (0, 0)), mode='constant')\n",
        "        padded_df[i, j] = padded_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDt8tpVA_RPM"
      },
      "outputs": [],
      "source": [
        "img = padded_df[9,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvo1WZsXCITE"
      },
      "outputs": [],
      "source": [
        "padded_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Mqf2uvn_V2D"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OijNCDgzRl2p"
      },
      "outputs": [],
      "source": [
        "pred = []\n",
        "for i in range(10):\n",
        "  for j in range(60):\n",
        "    pred.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y0ElZ5dR8Io"
      },
      "outputs": [],
      "source": [
        "pred = np.array(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8MhuV48STTe"
      },
      "outputs": [],
      "source": [
        "padded_df = padded_df.reshape(600, 500, 500, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz4-slgFSvjA"
      },
      "outputs": [],
      "source": [
        "img = padded_df[60]\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6upjz2zUoLZ"
      },
      "outputs": [],
      "source": [
        "padded_df_reshaped = padded_df.reshape(padded_df.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-ACCPR3V62p"
      },
      "outputs": [],
      "source": [
        "pred = to_categorical(pred,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9QJsHglV-ox"
      },
      "outputs": [],
      "source": [
        "#AI\n",
        "# # prompt: a tensorflow neural network that does a multi classification problem of 10 bird species:American crow, Dark eyed junco, Vermillion flycatcher, Western Grebe, Yellow Warbler, Cactus wren, Indigo Bunting, Eastern Towhee, California Gull, ruby throated hummingbird\n",
        "# model = 0\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(500, 500, 3)))\n",
        "# model.add(MaxPool2D((2, 2)))\n",
        "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(MaxPool2D((2, 2)))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "# model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "# early_stop = EarlyStopping(monitor='val_loss',patience=2,restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlJcIbQWVFQT"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_df_reshaped, pred, test_size=0.2, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wca63FPhVY4B"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(480, 500, 500, 3)\n",
        "X_test = X_test.reshape(120, 500, 500, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPL6UxJ8XKUN"
      },
      "outputs": [],
      "source": [
        "i = 100\n",
        "plt.imshow(X_test[i])\n",
        "print(y_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuuSjnkW14FF"
      },
      "outputs": [],
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jebsUGnVj66"
      },
      "outputs": [],
      "source": [
        "model = 0;\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=100 , kernel_size=(2,2),input_shape=(500, 500, 3), activation='relu',))#filters = 100\n",
        "model.add(MaxPool2D(pool_size=(7,7)))#(2,1)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1200, activation = \"relu\"))#1200, relu\n",
        "model.add(Dense(750, activation = \"relu\"))# relu 750\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience = 10,restore_best_weights=True)\n",
        "# # #neural network version 3\n",
        "\n",
        "# model = 0;\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(filters=64 , kernel_size=(2,2),input_shape=(500, 500, 3), activation='relu',))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(60))\n",
        "# model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "# model.add(Dense(95))\n",
        "# model.add(LeakyReLU(alpha = 0.01))\n",
        "\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "# model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "# early_stop = EarlyStopping(monitor='val_loss',patience = 100,restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# #neural network version 2\n",
        "# model = 0;\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(filters=64 , kernel_size=(2,2),input_shape=(500, 500, 3), activation='relu',))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(50))\n",
        "# model.add(LeakyReLU(alpha = 0.2))\n",
        "\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "# model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "# early_stop = EarlyStopping(monitor='val_loss',patience=25,restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n",
        "# #neural network version 1\n",
        "# model = 0;\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(filters= 64, kernel_size=(2,2),input_shape=(500, 500, 3), activation='relu',))#best filter: 64\n",
        "\n",
        "\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "# model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "# early_stop = EarlyStopping(monitor='val_loss',patience=6,restore_best_weights=True)\n",
        "\n",
        "# #neural network version 0\n",
        "# model = 0;\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(filters= 32, kernel_size=(4,4),input_shape=(500, 500, 3), activation='relu',))\n",
        "\n",
        "\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "# model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "# early_stop = EarlyStopping(monitor='val_loss',patience=2,restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYHG51v-Vldp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJBjyiEmWdxb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3ciYTPNRsuG"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test), callbacks = early_stop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4Snp5077p5D"
      },
      "outputs": [],
      "source": [
        "y_test_hat = model.predict(X_test)\n",
        "\n",
        "y_test_hat_cat = np.zeros_like(y_test_hat)\n",
        "y_test_hat_cat[np.arange(y_test_hat.shape[0]), np.argmax(y_test_hat, axis=1)] = 1\n",
        "print(classification_report(y_test, y_test_hat_cat))\n",
        "\n",
        "\n",
        "y_test_non_category = [ np.argmax(t) for t in y_test ]\n",
        "y_test_hat_non_category = [ np.argmax(t) for t in y_test_hat ]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(y_test_non_category, y_test_hat_non_category)\n",
        "draw_confusion_matrix(conf_mat, [0,1,2,3,4,5,6,7,8,9], \"version 4\")\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "plot_multiclass_roc(y_test, y_test_hat_cat, \"version 4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCgKmEQ4vlsO"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test, y_test_hat_cat)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbxmpOBATZey"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnV5169ESKHF"
      },
      "outputs": [],
      "source": [
        "print(conf_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbGAjyvxCMk1"
      },
      "outputs": [],
      "source": [
        "y_test_hat_cat[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzhQPoHlLlKd"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhEeES1zMiyQ"
      },
      "outputs": [],
      "source": [
        "plot_multiclass_roc(y_test, y_test_hat_cat)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "b2NuSsxqzEEZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}